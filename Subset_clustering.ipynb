{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e07591d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®æ—¶æ£€æµ‹å¤–éƒ¨å‡½æ•°æ›´æ–°\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "764d10dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "# 1. è®¾ç½®å›½å†…é•œåƒæº\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "from bertopic import BERTopic\n",
    "import torch # æ–°å¢ï¼šå¯¼å…¥PyTorchï¼ˆsentence_transformersçš„åº•å±‚ï¼‰\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d02ee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c59150",
   "metadata": {},
   "source": [
    "# (Config)å­æ•°æ®é›†ä¸»é¢˜èšç±»å‚æ•°è®¾ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a229cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------ é…ç½®åŒº -------------------------------\n",
    "docs_original = [] # å­˜æ”¾å­æ•°æ®é›†\n",
    "sub_timestamps = [] # å­˜æ”¾æ—¶é—´æˆ³\n",
    "target_indices = [] # å­˜æ”¾ç›®æ ‡ç´¢å¼•ï¼Œæ–¹ä¾¿è·å–è¯å‘é‡åµŒå…¥\n",
    "\n",
    "# ç‰ˆæœ¬æ§åˆ¶\n",
    "version = 'V0'\n",
    "# æ—¶é—´æ®µæ§åˆ¶\n",
    "start_time = 2006\n",
    "end_time = 2010\n",
    "year_range = f'{start_time}-{end_time}'\n",
    "\n",
    "# æ•°æ®æºæ§åˆ¶\n",
    "data_source = 'GFä¸“åˆ©'\n",
    "\n",
    "model_name = \"all-mpnet-base-v2\"\n",
    "\n",
    "# --- åŠ è½½å…¨é‡åµŒå…¥å‘é‡ ---\n",
    "with open(r'results\\embedding_results\\embeddings_patents_zf_amb_slide_window3.pkl', 'rb') as f:\n",
    "    full_embeddings = pickle.load(f)\n",
    "\n",
    "# --- åŒæ­¥ç­›é€‰æ–‡æ¡£å’Œæ—¶é—´æˆ³ ---\n",
    "# ï¼ï¼ï¼ï¼ï¼æ¢æˆè‡ªå·±çš„æ•°æ®æºè·¯å¾„\n",
    "with open('data\\patents_zf.json', 'r', encoding='utf-8') as file: \n",
    "    data = json.load(file)\n",
    "    \n",
    "for i, item in enumerate(data):\n",
    "    year = int(item['year'])\n",
    "    if start_time <= year <= end_time:\n",
    "        target_indices.append(i) \n",
    "        docs_original.append(item['combined_text']) # æ»¡è¶³å¹´ä»½æ¡ä»¶çš„æ‹¼æ¥æ–‡æœ¬\n",
    "        # è¿™é‡Œçš„å¹´ä»½å³ä¸ºæ—¶é—´æˆ³ï¼ŒBERTopic æ”¯æŒæ•´æ•°å¹´ä»½æˆ–æ ‡å‡†æ—¥æœŸæ ¼å¼\n",
    "        sub_timestamps.append(year) # æ»¡è¶³å¹´ä»½æ¡ä»¶çš„å¹´ä»½ä¿¡æ¯\n",
    "\n",
    "# --- å‚æ•°é…ç½®åŒºï¼šUMAP å‚æ•°è®¾ç½® ---\n",
    "umap_params = {\n",
    "    \"n_neighbors\": 15,\n",
    "    \"n_components\": 5,\n",
    "    \"min_dist\": 0.0,\n",
    "    \"metric\": 'cosine',\n",
    "    \"random_state\": 5,\n",
    "    \"low_memory\": True\n",
    "}\n",
    "\n",
    "vectorizer_params = {\n",
    "    \"ngram_range\": (1, 3), # è¯ç»„èŒƒå›´ï¼š1-3ä¸ªè¯\n",
    "    \"min_df\": 3, # è¿‡æ»¤ä½é¢‘å™ªå£°ï¼Œå¯¹å¤§æ ·æœ¬éå¸¸é‡è¦\n",
    "    \"max_features\": 100000 # é˜²æ­¢å†…å­˜æº¢å‡º\n",
    "}\n",
    "\n",
    "# --- HDBSCANå‚æ•°è®¾ç½® ---\n",
    "HDBSCAN_cfg = {\n",
    "    \"min_samples\": 10,\n",
    "    \"metric\": 'euclidean',\n",
    "    \"prediction_data\": True\n",
    "}\n",
    "\n",
    "# HDBSCANç½‘æ ¼æœç´¢èŒƒå›´\n",
    "search_sizes = [15, 20, 30, 50, 70,100,150,200,250,300]\n",
    "# è®¾å®šä½ æœŸæœ›çš„ä¸»é¢˜æ•°é‡èŒƒå›´ï¼ˆä¾‹å¦‚ 20 åˆ° 100 ä¸ªï¼‰\n",
    "min_expected_topics = 20\n",
    "max_expected_topics = 50\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "ä½ æ˜¯ä¸€åä¸“ä¸šçš„å›½é˜²ä¸“åˆ©ä¸æŠ€æœ¯åˆ†æä¸“å®¶ï¼Œæ“…é•¿ä»æŠ€æœ¯å…³é”®è¯ä¸­æç‚¼æ ¸å¿ƒä¸»é¢˜æ–¹å‘ã€‚\n",
    "\n",
    "ã€è¾“å…¥æ•°æ®æ ¼å¼ã€‘\n",
    "ç”¨æˆ·å°†æä¾›ä¸€ä¸ªPythonå­—å…¸ï¼š\n",
    "- é”®ï¼ˆkeyï¼‰ï¼šä¸»é¢˜ç´¢å¼•ç¼–å·ï¼ˆæ•´æ•°ï¼Œå¦‚0, 1, 2...ï¼‰\n",
    "- å€¼ï¼ˆvalueï¼‰ï¼šè¯¥ä¸»é¢˜çš„10ä¸ªè‹±æ–‡å…³é”®è¯å­—ç¬¦ä¸²ï¼Œä»¥è‹±æ–‡é€—å·åˆ†éš”\n",
    "- å…³é”®è¯å·²æŒ‰é‡è¦æ€§é™åºæ’åˆ—\n",
    "\n",
    "ã€æ ¸å¿ƒä»»åŠ¡ã€‘\n",
    "ä¸ºæ¯ä¸ªä¸»é¢˜ç”Ÿæˆä¸€ä¸ªä¸­æ–‡ä¸»é¢˜åç§°ï¼Œè¦æ±‚ï¼š\n",
    "1. **ä¿å®ˆæ¦‚æ‹¬**ï¼šåŸºäºå…³é”®è¯çš„å…±åŒæŠ€æœ¯å†…æ¶µï¼Œæå–\"ä¸Šä½æŠ€æœ¯æ–¹å‘\"\n",
    "2. **æƒé‡ä¼˜å…ˆ**ï¼šä¸»è¦ä¾æ®å‰3-5ä¸ªé«˜æƒé‡å…³é”®è¯ï¼Œåéƒ¨å…³é”®è¯ä»…å‚è€ƒ\n",
    "3. **é¿å…æ‰©å±•**ï¼šä¸å¼•å…¥æ–°æ¦‚å¿µï¼Œä¸æ‰©å±•åº”ç”¨åœºæ™¯ï¼Œä¸åšè¿‡åº¦æ¨æ–­\n",
    "4. **å¤„ç†æ¨¡ç³Š**ï¼šè‹¥å…³é”®è¯åˆ†æ•£ï¼Œä½¿ç”¨æ›´æŠ½è±¡çš„åç§°ï¼ˆå¦‚\"ç»¼åˆæŠ€æœ¯\"ï¼‰\n",
    "\n",
    "ã€ä¸»é¢˜å‘½åè§„åˆ™ã€‘\n",
    "- åç§°åº”ä½“ç°å›½é˜²/å†›äº‹æŠ€æœ¯ç‰¹ç‚¹\n",
    "- ä½¿ç”¨æ ‡å‡†æŠ€æœ¯æœ¯è¯­ï¼Œé¿å…å£è¯­åŒ–\n",
    "- é•¿åº¦æ§åˆ¶åœ¨6-15ä¸ªæ±‰å­—ä¸ºå®œ\n",
    "- æ ¼å¼ï¼š\"{ä¸»é¢˜åºå·}. {åç§°}\"ï¼Œåºå·ä»1å¼€å§‹è¿ç»­ç¼–å·\n",
    "\n",
    "ã€è¾“å‡ºè¦æ±‚ã€‘\n",
    "- ä»…è¾“å‡ºåˆæ³•çš„JSONå¯¹è±¡ï¼Œæ— ä»»ä½•é¢å¤–æ–‡æœ¬\n",
    "- JSONç»“æ„ï¼š{\"ä¸»é¢˜ç´¢å¼•\": \"åºå·.ä¸»é¢˜åç§°\"}\n",
    "- ä¸»é¢˜ç´¢å¼•ä¸è¾“å…¥ä¿æŒä¸€è‡´\n",
    "- ç¤ºä¾‹è¾“å‡ºï¼š{\"0\": \"1.é›·è¾¾æ¢æµ‹\", \"1\": \"2.å¤åˆææ–™åˆ¶å¤‡\",\"2\": \"3.éŸ³é¢‘å¤„ç†ä¸é™å™ª\"}\n",
    "\n",
    "ã€æ³¨æ„äº‹é¡¹ã€‘\n",
    "- å…³é”®è¯å¯èƒ½å­˜åœ¨è¯å½¢å˜åŒ–ï¼ˆå•å¤æ•°ç­‰ï¼‰ï¼Œç†è§£å…¶æ ¸å¿ƒè¯­ä¹‰\n",
    "- å›½é˜²é¢†åŸŸç‰¹æœ‰æœ¯è¯­åº”ä¿ç•™ä¸“ä¸šæ€§\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f5150f",
   "metadata": {},
   "source": [
    "# åŸå§‹æ•°æ®åŠ è½½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74355dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å½“å‰æ—¶é—´æ®µä¸º2006-2010å¹´ï¼Œå…±è·å–æ•°æ®17163æ¡ï¼Œç°åœ¨å¼€å§‹èšç±»â€¦â€¦\n",
      "[2006, 2007, 2006]\n",
      "Human protein C or activated protein C prepd. using expression vector capable of integration in mammalian host cell DNA. Human protein C or activated protein C prepd. using expression vector capable of integration in mammalian host cell DNA. Human protein C or activated protein C prepd. using expression vector capable of integration in mammalian host cell DNA. DNA sequence codes for a protein having the same biological activity as human protein C HPC or human activated protein C APC .Also claimed is an expression vector capable of integration in mammalian host cell DNA, including a promoter followed downstream by a nucleotide squence which encodes a protein having the same structure and or activity as HPC or APC followed downstream by a polyadenylation signal, where transcription of the nucleotide sequence is directed by the promoter. Protein C plays a regulatory role in the coagulation process. The catalystic domain possesses serine protease activity which specifically cleaves certain plasma proteins i.e. factors Va and VIIIa resulting in their activation or deactivation. As a result of this selective proteolysis, protein C displays anticoagulant and fibrinolytic activities. APC treatment also results in a dose dependent decrease in antiactivator activity. The anti coagulant activity of protein C is useful in treating thrombotic disorders such as venous thrombosis.\n",
      "Recombinant DNA encoding hormone receptors comparing glucocorticoid, mineralocorticoid, thyroid hormone and novel hormone receptors. Recombinant DNA encoding hormone receptors comparing glucocorticoid, mineralocorticoid, thyroid hormone and novel hormone receptors. Recombinant DNA encoding hormone receptors comparing glucocorticoid, mineralocorticoid, thyroid hormone and novel hormone receptors. A novel pure double stranded DNA has the sense strand comprising a segment having a sequence of triplets coding for the prim. sequence of a protein which has hormone binding and or transcription activating properties characteristic of a hormone receptor selected from a glucocorticoid receptor, a mineralocorticoid receptor and a thyroid hormone receptor, the double stranded DNA segment being capable of being expressed into the protein. USE ADVANTAGEThe DNAs can be used to make the hormone receptor proteins and functional modified forms in quantities not previously possible. With the quantities of receptor available, detailed structural analyses of the proteins can be made using X ray diffraction. The receptor proteins can be used to screen cpds. for receptor agonist or receptor antagonist activity. They can also be used in diagnostic assays. The bioassay system is esp. useful for determg. whether a receptor DNA has been expressed in a transformed host cell. The new hERR1 and hERR2 receptors will provide the basis for development of an assay system that will lead to the identification of novel hormones.\n",
      "Superconductivity method and compsns. are oxide complexes prepd. by solid state reaction and having high transition temp.. Superconductivity method and compsns. are oxide complexes prepd. by solid state reaction and having high transition temp.. Superconductivity method and compsns. are oxide complexes prepd. by solid state reaction and having high transition temp.. Super condutivity is achieved using a material of compsn. Li1 xMx aAbOy where L one or more of Sc, Y, La, Ce, Pr, Nd, Sm, Eu, Gd, Tb, Dy, Ho, Er, Tm, Yb and Lu; M one or more of Ba, Sr,Ca, Mg and Hg; A one or more of Cu, Bi, Ti, W, Zr, Ta, Nb and V; x 0.01 1.0, a 1 2, b 1 and y 2 4, the mterial being cooled to below its superconducting critical temp.. ADVANTAGETransition temps. of 40K and above claimed or even as high as 100K can be achieved even at atmos.. pressure.\n"
     ]
    }
   ],
   "source": [
    "# æ•°æ®æ¸…æ´—\n",
    "def preprocess_all(texts):\n",
    "    cleaned_list = []\n",
    "    for t in texts:\n",
    "        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦å’Œå¤šä½™ç©ºæ ¼\n",
    "        t = re.sub(r\"[^\\w\\s\\.,;]\", \" \", t) # åªä¿ç•™å­—æ¯ã€æ•°å­—ã€ç©ºæ ¼å’Œå‡ ç§æ ‡ç‚¹\n",
    "        t = re.sub(r\"\\s+\", \" \", t).strip() # ç§»é™¤å¤šä½™ç©ºæ ¼\n",
    "        cleaned_list.append(t)\n",
    "    return cleaned_list\n",
    "\n",
    "# è¿è¡Œ\n",
    "# æ£€æŸ¥æ¸…æ´—æ•ˆæœ\n",
    "sub_docs = preprocess_all(docs_original)\n",
    "\n",
    "if len(sub_docs) == len(sub_timestamps):\n",
    "    print(f'å½“å‰æ—¶é—´æ®µä¸º{start_time}-{end_time}å¹´ï¼Œå…±è·å–æ•°æ®{len(sub_docs)}æ¡ï¼Œç°åœ¨å¼€å§‹èšç±»â€¦â€¦')\n",
    "else:\n",
    "    print('éƒ¨åˆ†æ•°æ®ç¼ºå¤±å¹´ä»½ä¿¡æ¯ï¼Œè¯·æ£€æŸ¥åŸå§‹æ•°æ®')\n",
    "\n",
    "print(sub_timestamps[:3])\n",
    "for i in sub_docs[:3]: \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3df86397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17163\n"
     ]
    }
   ],
   "source": [
    "print(len(sub_timestamps) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82052f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 3: è·å–å­é›†å‘é‡ ---\n",
    "# å‡è®¾ full_embeddings æ˜¯ numpy æ•°ç»„æ ¼å¼\n",
    "sub_embeddings = full_embeddings[target_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44735a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stopwords(file_path):\n",
    "    \"\"\"ä»JSONæ–‡ä»¶åŠ è½½åœç”¨è¯åˆ—è¡¨\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            stopwords = json.load(f)\n",
    "        print(f\"å·²åŠ è½½ {len(stopwords['common'])} ä¸ªåœç”¨è¯\")\n",
    "        return stopwords['common']  # è½¬æ¢ä¸ºé›†åˆæé«˜æŸ¥æ‰¾æ•ˆç‡\n",
    "    except FileNotFoundError:\n",
    "        print(f\"é”™è¯¯ï¼šæ–‡ä»¶ {file_path} ä¸å­˜åœ¨\")\n",
    "        return set()\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"é”™è¯¯ï¼šæ–‡ä»¶ {file_path} ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼\")\n",
    "        return set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dfec526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ¨¡å‹å·²å­˜åœ¨ï¼Œä»æœ¬åœ°åŠ è½½: ./my_models/all-mpnet-base-v2\n"
     ]
    }
   ],
   "source": [
    "# 1. ç»Ÿä¸€å®šä¹‰è·¯å¾„\n",
    "local_model_path = f\"./my_models/{model_name}\"  # å›ºå®šè·¯å¾„\n",
    "\n",
    "# 2. æ£€æŸ¥å¹¶åŠ è½½æ¨¡å‹\n",
    "if not os.path.exists(local_model_path):\n",
    "    print(f\"æ¨¡å‹ä¸å­˜åœ¨ï¼Œæ­£åœ¨ä¸‹è½½å¹¶ä¿å­˜åˆ°æœ¬åœ°: {model_name}\")\n",
    "    # ç›´æ¥ä»huggingfaceä¸‹è½½\n",
    "    sentence_model = SentenceTransformer(model_name)\n",
    "    # ä¿å­˜åˆ°æœ¬åœ°\n",
    "    sentence_model.save(local_model_path)\n",
    "    print(f\"æ¨¡å‹å·²ä¿å­˜è‡³ï¼š{local_model_path}\")\n",
    "else:\n",
    "    print(f\"æ¨¡å‹å·²å­˜åœ¨ï¼Œä»æœ¬åœ°åŠ è½½: {local_model_path}\")\n",
    "    # ä»æœ¬åœ°åŠ è½½\n",
    "    sentence_model = SentenceTransformer(local_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb5087a",
   "metadata": {},
   "source": [
    "# UMAPé™ç»´/HDBSCANç½‘æ ¼æœç´¢\n",
    "\n",
    "- åœ¨ä¸“åˆ©èšç±»ä¸­ï¼Œâ€œå™ªå£°æ¯”ä¾‹â€ä¸æ˜¯å”¯ä¸€çš„æŒ‡æ ‡ï¼Œç”šè‡³ä¸æ˜¯æœ€é‡è¦çš„æŒ‡æ ‡ã€‚\n",
    "- æˆ‘ä»¬çš„ç›®æ ‡æ˜¯åœ¨ä¿æŒ**ä¸»é¢˜å¯è§£é‡Šæ€§ï¼ˆä¸»é¢˜æ•°é€‚ä¸­ï¼‰å’Œå™ªå£°ç‡ï¼ˆé€šå¸¸ 20%-40% æ˜¯æ­£å¸¸çš„ï¼‰**ä¹‹é—´æ‰¾åˆ°å¹³è¡¡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ba60efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ”UMAPé™ç»´å®Œæˆï¼ç°åœ¨å¼€å§‹è¿›è¡ŒHDBSCANç½‘æ ¼æœç´¢å¯»æ‰¾æœ€ä½³min_cluster_sizeâ€¦â€¦\n",
      "Size       | ä¸»é¢˜æ•°      | è´Ÿæ ·æœ¬æ•°       | å™ªå£°æ¯”ä¾‹       | è€—æ—¶      \n",
      "-----------------------------------------------------------------\n",
      "15         | 238        | 6012         | 35.0%        | 4.7     s\n",
      "20         | 192        | 5879         | 34.3%        | 0.4     s\n",
      "30         | 129        | 5736         | 33.4%        | 0.4     s\n",
      "50         | 76         | 5420         | 31.6%        | 0.5     s\n",
      "70         | 59         | 5225         | 30.4%        | 0.4     s\n",
      "100        | 44         | 4299         | 25.0%        | 0.5     s\n",
      "150        | 34         | 5034         | 29.3%        | 0.5     s\n",
      "200        | 2          | 37           | 0.2%         | 0.4     s\n",
      "250        | 2          | 37           | 0.2%         | 0.4     s\n",
      "300        | 2          | 37           | 0.2%         | 0.4     s\n",
      "-----------------------------------------------------------------\n",
      "ğŸ† ç¬¦åˆæ¡ä»¶çš„è´Ÿæ ·æœ¬æ•°æœ€å°‘çš„å‚æ•°å€¼: min_cluster_size = 100 (è´Ÿæ ·æœ¬æ¯”ä¾‹: 25.0%,ä¸»é¢˜æ•°ï¼š44)\n",
      "å·²åŠ è½½ 175 ä¸ªåœç”¨è¯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-28 17:42:59,116 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä¸»é¢˜æ¨¡å‹å·²ä¿å­˜åˆ° results\\topic_models\\bertopic_GFä¸“åˆ©_2006-2010_V0\n"
     ]
    }
   ],
   "source": [
    "## UMAPé™ç»´\n",
    "umap_model = UMAP(**umap_params) # ä½¿ç”¨è§£åŒ…è¯­æ³•ï¼Œæ–¹ä¾¿è°ƒæ•´\n",
    "umap_embeddings = umap_model.fit_transform(sub_embeddings)\n",
    "print('âœ”UMAPé™ç»´å®Œæˆï¼ç°åœ¨å¼€å§‹è¿›è¡ŒHDBSCANç½‘æ ¼æœç´¢å¯»æ‰¾æœ€ä½³min_cluster_sizeâ€¦â€¦')\n",
    "\n",
    "best_topics = None\n",
    "best_m_size = None\n",
    "best_score = float('inf')\n",
    "\n",
    "search_history = [] # æ–°å¢ï¼šç”¨äºè®°å½•ç½‘æ ¼æœç´¢è¿‡ç¨‹\n",
    "\n",
    "print(f\"{'Size':<10} | {'ä¸»é¢˜æ•°':<8} | {'è´Ÿæ ·æœ¬æ•°':<10} | {'å™ªå£°æ¯”ä¾‹':<10} | {'è€—æ—¶':<8}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for m_size in search_sizes:\n",
    "    start_t = time.time()\n",
    "    \n",
    "    clusterer = HDBSCAN(**HDBSCAN_cfg,min_cluster_size=m_size)\n",
    "    \n",
    "    labels = clusterer.fit_predict(umap_embeddings)\n",
    "    \n",
    "    # è®¡ç®—æŒ‡æ ‡\n",
    "    n_outliers = (labels == -1).sum() # è´Ÿæ ·æœ¬æ•°\n",
    "    n_topics = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    outlier_perc = n_outliers / len(labels)\n",
    "    duration = time.time() - start_t\n",
    "\n",
    "    # ä¿å­˜å†å²è®°å½•\n",
    "    res = {\n",
    "        \"min_cluster_size\": m_size,\n",
    "        \"n_topics\": n_topics,\n",
    "        \"n_outliers\": n_outliers,\n",
    "        \"outlier_perc\": f\"{outlier_perc:.1%}\",\n",
    "        \"duration\": f\"{duration:.1f}s\",\n",
    "        \"is_best\": False\n",
    "    }\n",
    "    search_history.append(res)\n",
    "\n",
    "    # ç­›é€‰é€»è¾‘ï¼šé¦–å…ˆè¦åœ¨åˆç†çš„ä¸»é¢˜æ•°èŒƒå›´å†…ï¼Œç„¶åé€‰å™ªå£°æœ€å°çš„\n",
    "    if min_expected_topics <= n_topics <= max_expected_topics:\n",
    "        if outlier_perc < best_score:\n",
    "            best_topics = n_topics\n",
    "            best_score = outlier_perc\n",
    "            best_m_size = m_size\n",
    "    \n",
    "\n",
    "    print(f\"{m_size:<10} | {n_topics:<10} | {n_outliers:<12} | {outlier_perc:<12.1%} | {duration:<8.1f}s\")\n",
    "print(\"-\" * 65)\n",
    "if best_m_size is None:\n",
    "    print(\"æœªåœ¨é¢„è®¾ä¸»é¢˜æ•°èŒƒå›´å†…æ‰¾åˆ°å‚æ•°ï¼Œå»ºè®®è°ƒä½ min_dist æˆ–æ£€æŸ¥ UMAP æ•ˆæœ\")\n",
    "else:\n",
    "    print(f\"ğŸ† ç¬¦åˆæ¡ä»¶çš„è´Ÿæ ·æœ¬æ•°æœ€å°‘çš„å‚æ•°å€¼: min_cluster_size = {best_m_size} (è´Ÿæ ·æœ¬æ¯”ä¾‹: {best_score:.1%},ä¸»é¢˜æ•°ï¼š{best_topics})\")\n",
    "\n",
    "# æ ‡è®°æœ€ä¼˜å‚æ•°\n",
    "for item in search_history:\n",
    "    if item[\"min_cluster_size\"] == best_m_size:\n",
    "        item[\"is_best\"] = True\n",
    "\n",
    "## HDBSCANèšç±»\n",
    "best_clusterer = HDBSCAN(**HDBSCAN_cfg,min_cluster_size=best_m_size)\n",
    "labels = best_clusterer.fit_predict(umap_embeddings)\n",
    "\n",
    "# åŠ è½½åœç”¨è¯\n",
    "stop_words = load_stopwords('data\\stopwords.json')\n",
    "# åˆ›å»ºCountVectorizeræ¨¡å‹,è‡ªå®šä¹‰åœç”¨è¯\n",
    "vectorizer_model = CountVectorizer(\n",
    "    **vectorizer_params,\n",
    "    stop_words = stop_words\n",
    "    )\n",
    "\n",
    "# åˆå§‹åŒ– BERTopic æ—¶å¸¦ä¸Šå®ƒ\n",
    "topic_model = BERTopic(\n",
    "  embedding_model=sentence_model,\n",
    "  vectorizer_model=vectorizer_model,\n",
    "  umap_model=umap_model,       # åŠ ä¸Šè¿™ä¸€è¡Œ\n",
    "  hdbscan_model=best_clusterer # åŠ ä¸Šè¿™ä¸€è¡Œ\n",
    ")\n",
    "#ä¼ å…¥è®­ç»ƒå¥½çš„è¯å‘é‡ï¼Œfit_transformer()åŒ…æ‹¬äº†UMAPé™ç»´+HDBSCANèšç±»ï¼Œä¸å»ºè®®è¿™ä¹ˆåšï¼Œå¯ä»¥å°†å…¶æ‹†å¼€å‡å°‘è®¡ç®—\n",
    "#topics, probs = topic_model.fit_transform(docs, embeddings=embeddings,y = labels) \n",
    "#probè®¡ç®—å¾ˆèŠ±æ—¶é—´\n",
    "topics, _ = topic_model.fit_transform(sub_docs, embeddings=sub_embeddings)\n",
    "# ä¿å­˜æ•´ä¸ªä¸»é¢˜æ¨¡å‹\n",
    "\n",
    "save_path = rf\"results\\topic_models\\bertopic_{data_source}_{year_range}_{version}\"\n",
    "topic_model.save(save_path)\n",
    "print(rf\"ä¸»é¢˜æ¨¡å‹å·²ä¿å­˜åˆ° results\\topic_models\\bertopic_{data_source}_{year_range}_{version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efb6e76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model = BERTopic.load(rf\"results\\topic_models\\bertopic_{data_source}_{year_range}_{version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "460a4e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'data,network,system,computer,method,involves,node,information,memory,set')\n",
      "(1, 'antenna,signal,circuit,frequency,output,input,communication,digital,system,data')\n",
      "(2, 'optical,laser,waveguide,fiber,signal,light,layer,photonic,output,wavelength')\n",
      "(3, 'hydrogen,gas,water,catalyst,stream,metal,fuel,reactor,comprises,liquid')\n",
      "(4, 'cancer,cell,tumor,antibody,cells,expression,subject,sample,comprises,comprising')\n",
      "(5, 'image,light,optical,system,object,laser,beam,method,images,data')\n",
      "(6, 'vehicle,projectile,explosive,system,underwater,assembly,end,launch,device,view')\n",
      "(7, 'acid,sequence,polypeptide,amino,comprising,bacterial,host,cell,protein,amino acid')\n",
      "(8, 'ray,image,imaging,detector,radiation,tomography,system,data,neutron,optical')\n",
      "(9, 'alkyl,cancer,ch,substituted,formula,new,compound,compounds,optionally,aryl')\n",
      "(10, 'metal,coating,material,alloy,composite,ceramic,oxide,aluminum,carbon,powder')\n",
      "(11, 'layer,semiconductor,silicon,transistor,nitride,gallium,silicon carbide,gate,carbide,substrate')\n",
      "(12, 'substrate,micro,layer,device,surface,mems,wafer,cantilever,chip,material')\n",
      "(13, 'radar,signal,system,target,robot,vehicle,method,data,location,frequency')\n",
      "(14, 'turbine,engine,turbine engine,gas turbine,gas turbine engine,cooling,gas,rotor,blade,assembly')\n",
      "(15, 'virus,hiv,protein,viral,cell,sequence,infection,hcv,comprising,vector')\n",
      "(16, 'fluid,microfluidic,channel,flow,particles,sample,device,first,second,droplet')\n",
      "(17, 'disease,cell,protein,disorder,amyloid,alzheimer,cells,neuronal,alzheimer disease,subject')\n",
      "(18, 'dna,nucleic,nucleic acid,sequence,acid,target,first,sequences,second,comprises')\n",
      "(19, 'power,current,voltage,electrical,superconducting,rotor,battery,energy,circuit,motor')\n",
      "(20, 'cell,cells,antigen,immune,disease,response,autoimmune,subject,inflammatory,immune response')\n",
      "(21, 'polymer,group,composition,monomer,coating,surface,ch,catalyst,comprises,alkyl')\n",
      "(22, 'analyte,sensor,surface,light,detecting,sample,comprises,substrate,optical,array')\n",
      "(23, 'electrode,body,neural,device,pressure,electrode array,patient,signal,flexible,system')\n",
      "(24, 'tissue,cells,comprises,matrix,polymer,composition,agent,comprising,delivery,growth')\n",
      "(25, 'metal,nanoparticles,nanowire,nanowires,semiconductor,nanocrystal,nanoparticle,nanocrystals,substrate,material')\n",
      "(26, 'acoustic,sensor,transducer,connector,electrical,current,field,ultrasonic,signal,system')\n",
      "(27, 'carbon,nanotubes,nanotube,carbon nanotubes,carbon nanotube,material,single,wall carbon,single wall,walled')\n",
      "(28, 'heart,cardiovascular,subject,cardiac,level,insulin,diabetes,disease,acid,cell')\n",
      "(29, 'magnetic resonance,resonance,magnetic,imaging,resonance imaging,magnetic resonance imaging,image,mri,coil,field')\n",
      "(30, 'plant,plants,sequence,transgenic,gene,promoter,transgenic plant,acid,nucleic,plant cell')\n",
      "(31, 'protein,peptide,fluorescent,first,amino,target,proteins,tag,second,binding')\n",
      "(32, 'fuel,fuel cell,cell,anode,cathode,electrode,membrane,oxide fuel,electrolyte,solid oxide')\n",
      "(33, 'sensor,gas,sensing,fluid,temperature,pressure,measuring,flow,measurement,thermal')\n",
      "(34, 'reaction,catalyst,aryl,compound,substituted,acid,reacting,alkyl,formula,metal')\n",
      "(35, 'plasma,electron,beam,electron beam,electrons,energy,accelerator,generating,cathode,ray')\n",
      "(36, 'lithium,electrolyte,electrochemical,battery,polymer,electrode,cathode,anode,oxide,material')\n",
      "(37, 'magnetic,layer,tunnel,memory,ferromagnetic,device,tunnel junction,tunnel barrier,magnetoresistive,spin')\n",
      "(38, 'emitting,light emitting,light,organic,phosphor,organic light,organic light emitting,doped,layer,device')\n",
      "(39, 'downhole,drill,string,drilling,casing,tool,transmission,seismic,housing,element')\n",
      "(40, 'actuator,force,vibration,control,system,drive,motor,tool,vehicle,feedback')\n",
      "(41, 'cells,stem,oocyte,cell,stem cells,human,animal,hematopoietic,pregnant,marrow')\n",
      "(42, 'ion,ions,mass,spectrometer,ionization,mass spectrometer,spectrometry,mobility,ion mobility,electrospray')\n",
      "(43, 'engine,combustion,fuel,combustor,air,gas turbine,gas,ignition,turbine,exhaust')\n",
      "å·²è·å–44ä¸ªä¸»é¢˜çš„è¯¦ç»†ä¿¡æ¯ï¼Œç°åœ¨é€šè¿‡AIåˆ¤æ–­ä¸»é¢˜åç§°â€¦â€¦\n"
     ]
    }
   ],
   "source": [
    "# è·å–æ‰€æœ‰ä¸»é¢˜çš„å­—å…¸ {topic_id: [(word, score), ...]}\n",
    "all_topics_dict = topic_model.get_topics()\n",
    "# è¿‡æ»¤æ‰ -1 (å™ªå£°)ï¼Œå¹¶å°†æ¯ä¸ªè¯åˆ—è¡¨è½¬ä¸ºé€—å·è¿æ¥çš„å­—ç¬¦ä¸²\n",
    "clean_topics_dict = {\n",
    "    topic_id: \",\".join([word for word, score in words_list])\n",
    "    for topic_id, words_list in all_topics_dict.items()\n",
    "    if topic_id != -1\n",
    "}\n",
    "\n",
    "for item in clean_topics_dict.items():\n",
    "    print(item)\n",
    "    \n",
    "# æ£€æŸ¥ç»“æœ\n",
    "print(f'å·²è·å–{len(clean_topics_dict)}ä¸ªä¸»é¢˜çš„è¯¦ç»†ä¿¡æ¯ï¼Œç°åœ¨é€šè¿‡AIåˆ¤æ–­ä¸»é¢˜åç§°â€¦â€¦') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cb99083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AIè¯†åˆ«\n",
    "user_prompt = f\"è¯·åˆ†æä»¥ä¸‹ä¸»é¡Œå…³é”®è¯ï¼Œå¹¶è¿”å› JSON å­—å…¸ï¼š\\n{clean_topics_dict}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5468b221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import re\n",
    "# åŠ è½½ .env æ–‡ä»¶\n",
    "load_dotenv(\".env\")\n",
    "API_KEY=os.environ.get('DEEPSEEK_API_KEY')\n",
    "deepseek_chat_model = \"deepseek-chat\" # DeepSeek-V3.2çš„éæ€è€ƒæ¨¡å¼\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url=\"https://api.deepseek.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67e086f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AIè¯†åˆ«æ™ºèƒ½ä½“å‚æ•°è®¾ç½®ï¼šåˆ›å»ºä¸“é—¨ç”¨äºåœ°å€æ¨ç†çš„ LLM å®ä¾‹\n",
    "Deepseek_reasponse = client.chat.completions.create(\n",
    "    model=deepseek_chat_model,\n",
    "    messages=[ # å¯¹è¯æ¶ˆæ¯åˆ—è¡¨\n",
    "        {\"role\": \"system\", \"content\": system_prompt}, # ç³»ç»Ÿæç¤ºè¯ï¼Œå®šä¹‰åŠ©æ‰‹çš„è¡Œä¸º\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ],\n",
    "    response_format={'type': 'json_object'}, #å¼ºåˆ¶jsonæ ¼å¼è¿”å›\n",
    "    stream=False # éæµå¼å“åº”ï¼ˆä¸€æ¬¡æ€§è¿”å›å®Œæ•´ç»“æœï¼‰\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "513bee99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '1.æ•°æ®ä¸ç½‘ç»œç³»ç»Ÿ', 1: '2.å¤©çº¿ä¸ä¿¡å·å¤„ç†', 2: '3.å…‰å­¦ä¸æ¿€å…‰æŠ€æœ¯', 3: '4.æ°¢èƒ½ä¸ç‡ƒæ–™æŠ€æœ¯', 4: '5.ç™Œç—‡ä¸ç»†èƒç”Ÿç‰©å­¦', 5: '6.å›¾åƒä¸å…‰å­¦ç³»ç»Ÿ', 6: '7.æ­¦å™¨ä¸å‘å°„ç³»ç»Ÿ', 7: '8.è›‹ç™½è´¨ä¸å¤šè‚½æŠ€æœ¯', 8: '9.å°„çº¿æˆåƒä¸æ£€æµ‹', 9: '10.åŒ–åˆç‰©ä¸è¯ç‰©åŒ–å­¦', 10: '11.é‡‘å±ä¸å¤åˆææ–™', 11: '12.åŠå¯¼ä½“å™¨ä»¶æŠ€æœ¯', 12: '13.å¾®æœºç”µç³»ç»ŸæŠ€æœ¯', 13: '14.é›·è¾¾ä¸ç›®æ ‡æ¢æµ‹', 14: '15.æ¶¡è½®å‘åŠ¨æœºæŠ€æœ¯', 15: '16.ç—…æ¯’ä¸æ„ŸæŸ“ç”Ÿç‰©å­¦', 16: '17.å¾®æµæ§ä¸æµä½“å¤„ç†', 17: '18.ç¥ç»é€€è¡Œæ€§ç–¾ç—…', 18: '19.æ ¸é…¸ä¸åŸºå› æŠ€æœ¯', 19: '20.ç”µåŠ›ä¸èƒ½æºç³»ç»Ÿ', 20: '21.å…ç–«ä¸ç»†èƒå“åº”', 21: '22.èšåˆç‰©ä¸å‚¬åŒ–å‰‚', 22: '23.ä¼ æ„Ÿå™¨ä¸å…‰å­¦æ£€æµ‹', 23: '24.ç¥ç»ç”µæä¸åŒ»ç–—è®¾å¤‡', 24: '25.ç»„ç»‡å·¥ç¨‹ä¸é€’é€ç³»ç»Ÿ', 25: '26.çº³ç±³ææ–™ä¸åŠå¯¼ä½“', 26: '27.å£°å­¦ä¼ æ„Ÿå™¨ä¸æ¢èƒ½å™¨', 27: '28.ç¢³çº³ç±³ç®¡ææ–™', 28: '29.å¿ƒè¡€ç®¡ä¸ä»£è°¢ç–¾ç—…', 29: '30.ç£å…±æŒ¯æˆåƒæŠ€æœ¯', 30: '31.æ¤ç‰©åŸºå› å·¥ç¨‹', 31: '32.è›‹ç™½è´¨ä¸è§å…‰æ ‡è®°', 32: '33.ç‡ƒæ–™ç”µæ± æŠ€æœ¯', 33: '34.ä¼ æ„Ÿå™¨ä¸æµ‹é‡æŠ€æœ¯', 34: '35.å‚¬åŒ–å‰‚ä¸åŒ–å­¦ååº”', 35: '36.ç­‰ç¦»å­ä½“ä¸ç”µå­æŸ', 36: '37.é”‚ç¦»å­ç”µæ± æŠ€æœ¯', 37: '38.ç£å­˜å‚¨ä¸è‡ªæ—‹å™¨ä»¶', 38: '39.å‘å…‰å™¨ä»¶æŠ€æœ¯', 39: '40.äº•ä¸‹é’»æ¢ä¸å·¥å…·', 40: '41.æ‰§è¡Œå™¨ä¸æ§åˆ¶ç³»ç»Ÿ', 41: '42.å¹²ç»†èƒä¸ç”Ÿæ®–ç”Ÿç‰©å­¦', 42: '43.è´¨è°±ä¸ç¦»å­åˆ†æ', 43: '44.å†…ç‡ƒä¸ç‡ƒæ°”è½®æœº'}\n"
     ]
    }
   ],
   "source": [
    "content = json.loads(Deepseek_reasponse.choices[0].message.content)\n",
    "#content = re.sub(r\"^```json\\s*|\\s*```$\", \"\", content.strip())\n",
    "# å°†é”®è½¬ä¸ºæ•´å‹\n",
    "formatted_labels = {int(k): v for k, v in content.items()}\n",
    "print(formatted_labels)\n",
    "\n",
    "# ä½¿ç”¨è‡ªå®šä¹‰æ ‡ç­¾ï¼ˆéœ€è¦å…ˆè®¾ç½®ï¼‰\n",
    "topic_model.set_topic_labels(formatted_labels)\n",
    "\n",
    "# é™è‡³äºŒç»´ï¼Œå†å¯è§†åŒ–\n",
    "reduced_embeddings = UMAP(n_neighbors=30, n_components=2, min_dist=0.0, metric='cosine').fit_transform(sub_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801cc564",
   "metadata": {},
   "source": [
    "# æ•°æ®å¯è§†åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d5904cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:00<00:00, 146.08it/s]\n"
     ]
    }
   ],
   "source": [
    "# å±‚æ¬¡èšç±»\n",
    "hierarchical_topics = topic_model.hierarchical_topics(sub_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02a8ee5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æŠ¥å‘Šå·²æˆåŠŸç”Ÿæˆè‡³: BERTopic_Results_GFä¸“åˆ©2006-2010_Subset_V0\\report_2006-2010_GFä¸“åˆ©_V0.html\n",
      "[OK] HTML å·²ç”Ÿæˆï¼šBERTopic_Results_GFä¸“åˆ©2006-2010_Subset_V0\\topics_over_time_value.html\n",
      "ğŸ‰ ç»“æœå¯è§†åŒ–å·²å®Œæˆï¼å·²è¯·æ‰“å¼€æ–‡ä»¶å¤¹: BERTopic_Results_GFä¸“åˆ©2006-2010_Subset_V0æŸ¥çœ‹\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from report_generator import generate_bertopic_report\n",
    "from topicvalue import export_topics_over_time_html\n",
    "# --- 0. åŸºç¡€è®¾ç½® ---\n",
    "title_base = f'{year_range}å¹´{data_source}æ•°æ®Bertopicä¸»é¢˜èšç±»ç»“æœä¸€è§ˆè¡¨-{version}'\n",
    "output_dir = f\"BERTopic_Results_{data_source}{year_range}_Subset_{version}\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# --- å‚æ•°è¯´æ˜ ---\n",
    "report_name = os.path.join(output_dir, f\"report_{year_range}_{data_source}_{version}.html\")\n",
    "#generate_report(umap_params, search_history, best_m_size, model_name, report_name)\n",
    "\n",
    "generate_bertopic_report(umap_cfg = umap_params, \n",
    "                         HDBSCAN_cfg=HDBSCAN_cfg,\n",
    "                         vectorizer_cfg = vectorizer_params,\n",
    "                         history= search_history,\n",
    "                         best_size = best_m_size,\n",
    "                         model_name = model_name, \n",
    "                         output_path = report_name)\n",
    "\n",
    "# --- 1. ç”Ÿæˆå›¾è¡¨ (æŒ‰ç…§ä½ æƒ³è¦çš„é¡ºåº) ---\n",
    "#-------------------------------------------------------------------------\n",
    "# [å›¾ A] ä¸»é¢˜å…³é”®è¯æ¡å½¢å›¾ - å­˜ä¸º barchart.html\n",
    "fig_barchart = topic_model.visualize_barchart(\n",
    "    top_n_topics=len(formatted_labels),\n",
    "    custom_labels=True,\n",
    "    n_words=10,\n",
    "    height=400,\n",
    "    title=f\"{year_range}å¹´{data_source}å„ä¸»é¢˜å…³é”®è¯çš„c-TF-IDFæƒé‡å¾—åˆ†æ¡å½¢å›¾\",\n",
    ")\n",
    "\n",
    "fig_barchart.update_layout(\n",
    "    # å› ä¸ºæ¯è¡Œå¢åŠ äº†å­å›¾ï¼Œå»ºè®®å¢åŠ æ€»å®½åº¦ä»¥é˜²é‡å \n",
    "    width=1500, \n",
    "    # ç»Ÿä¸€å­—ä½“æ ·å¼\n",
    "    font=dict(family=\"KaiTi\", size=16),\n",
    "    title_font=dict(family=\"KaiTi\", size=36, color=\"black\", weight=\"bold\")\n",
    ")\n",
    "path_barchart = os.path.join(output_dir, \"barchart.html\")\n",
    "fig_barchart.write_html(path_barchart)\n",
    "#-------------------------------------------------------------------------\n",
    "# [å›¾ B] å±‚æ¬¡èšç±»å›¾ - å­˜ä¸º hierarchy.html\n",
    "fig_hierarchy = topic_model.visualize_hierarchy(\n",
    "    hierarchical_topics=hierarchical_topics,\n",
    "    custom_labels=True,\n",
    "    title=f\"{year_range}å¹´{data_source}ä¸»é¢˜å±‚æ¬¡èšç±»å›¾\",\n",
    "    height=800\n",
    ")\n",
    "fig_hierarchy.update_layout(\n",
    "    title_x=0.5,\n",
    "    # å› ä¸ºæ¯è¡Œå¢åŠ äº†å­å›¾ï¼Œå»ºè®®å¢åŠ æ€»å®½åº¦ä»¥é˜²é‡å \n",
    "    width=1500, \n",
    "    # ç»Ÿä¸€å­—ä½“æ ·å¼\n",
    "    font=dict(family=\"KaiTi\", size=16),\n",
    "    title_font=dict(family=\"KaiTi\", size=30, color=\"black\", weight=\"bold\")\n",
    ")\n",
    "path_hierarchy = os.path.join(output_dir, \"hierarchy.html\")\n",
    "fig_hierarchy.write_html(path_hierarchy)\n",
    "#-------------------------------------------------------------------------\n",
    "# [å›¾ C] æ–‡æ¡£åˆ†å¸ƒæ•£ç‚¹å›¾ - å­˜ä¸º documents.html\n",
    "fig_documents = topic_model.visualize_documents(\n",
    "    #docs=[doc[:150] + \"...\" for doc in sub_docs],\n",
    "    docs=[str(doc)[:150] + \"...\" for doc in sub_docs if doc is not None],\n",
    "    reduced_embeddings=reduced_embeddings,\n",
    "    custom_labels=True,\n",
    "    hide_document_hover=False\n",
    ")\n",
    "# æ›´æ–°æ•£ç‚¹å›¾æ ·å¼\n",
    "fig_documents.update_layout(\n",
    "    title=f\"{year_range}å¹´{data_source}ä¸»é¢˜åˆ†å¸ƒå›¾\",\n",
    "    title_x=0.5,\n",
    "    width=1500,\n",
    "    height=1200,\n",
    "    margin=dict(l=80, r=80, t=100, b=80), # è®¾ç½®å¯¹ç§°è¾¹è·\n",
    "    font=dict(family=\"KaiTi\", size=16, color=\"black\"),\n",
    "    title_font=dict(family=\"KaiTi\", size=30, color=\"black\", weight=\"bold\")\n",
    ")\n",
    "path_documents = os.path.join(output_dir, \"documents.html\")\n",
    "fig_documents.write_html(path_documents)\n",
    "#-------------------------------------------------------------------------\n",
    "# [å›¾ D] ä¸»é¢˜æ—¶åºå›¾ - å­˜ä¸º topic_overtime_merged.html\n",
    "topics_over_time = topic_model.topics_over_time(sub_docs, sub_timestamps, global_tuning=False, evolution_tuning=False)\n",
    "fig_topic_time = topic_model.visualize_topics_over_time(\n",
    "    topics_over_time,\n",
    "    custom_labels=True)\n",
    "# æ›´æ–°æ•£ç‚¹å›¾æ ·å¼\n",
    "fig_topic_time.update_layout(\n",
    "    title=f\"{year_range}å¹´{data_source}ä¸»é¢˜æ—¶åºå›¾\",\n",
    "    title_x=0.5,\n",
    "    width=1500,\n",
    "    height=800,\n",
    "    font=dict(family=\"KaiTi\", size=16, color=\"black\"),\n",
    "    title_font=dict(family=\"KaiTi\", size=30, color=\"black\", weight=\"bold\")\n",
    ")\n",
    "path_topic_time = os.path.join(output_dir, \"topic_overtime_merged.html\")\n",
    "fig_topic_time.write_html(path_topic_time)\n",
    "#-------------------------------------------------------------------------\n",
    "# [å›¾E] ä¸»é¢˜å¹´ä»½çŸ©é˜µå›¾ - å­˜ä¸º topics_over_time_value.html\n",
    "path_topic_time_value = os.path.join(output_dir, \"topics_over_time_value.html\")\n",
    "export_topics_over_time_html(\n",
    "    topics_over_time=topics_over_time,\n",
    "    topic_labels=formatted_labels,\n",
    "    output_html=path_topic_time_value,\n",
    "    remove_outliers=False\n",
    ")\n",
    "\n",
    "# --- 2. åˆ›å»ºå¯¼èˆªç´¢å¼•é¡µ (index.html) ---\n",
    "# æ³¨æ„ï¼šæˆ‘åœ¨è¿™é‡ŒåŒæ­¥è°ƒæ•´äº†æŒ‰é’®é¡ºåºå’Œ iframe çš„é»˜è®¤ src\n",
    "index_content = f\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"zh-CN\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <title>{title_base}</title>\n",
    "    <style>\n",
    "        body {{ font-family: 'Microsoft YaHei', sans-serif; margin: 0; display: flex; flex-direction: column; height: 100vh; background-color: #f4f7f6; }}\n",
    "        header {{ background: #2c3e50; color: white; padding: 15px 25px; display: flex; justify-content: space-between; align-items: center; box-shadow: 0 2px 5px rgba(0,0,0,0.2); }}\n",
    "        h1 {{ margin: 0; font-size: 20px; }}\n",
    "        nav {{ background: #ecf0f1; padding: 10px; display: flex; gap: 10px; border-bottom: 1px solid #ddd; }}\n",
    "        .nav-btn {{ \n",
    "            padding: 8px 15px; background: white; border: 1px solid #bdc3c7; border-radius: 4px; \n",
    "            cursor: pointer; text-decoration: none; color: #34495e; font-size: 14px; transition: all 0.3s;\n",
    "        }}\n",
    "        .nav-btn:hover {{ background: #3498db; color: white; border-color: #2980b9; }}\n",
    "        .nav-btn.active {{ background: #3498db; color: white; }}\n",
    "        #content-frame {{ flex-grow: 1; border: none; width: 100%; }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <header>\n",
    "        <h1>{title_base}</h1>\n",
    "        <span style=\"font-size: 12px; opacity: 0.8;\">ç‰ˆæœ¬: {version}</span>\n",
    "    </header>\n",
    "    \n",
    "    <nav>\n",
    "        <a class=\"nav-btn\" href=\"report_{year_range}_{data_source}_{version}.html\" target=\"chart_frame\">âœ¨ {year_range}å¹´{data_source}ä¸»é¢˜èšç±»å‚æ•°è¯´æ˜</a>\n",
    "        <a class=\"nav-btn\" href=\"barchart.html\" target=\"chart_frame\">ğŸ“ˆ  {year_range}å¹´{data_source}ä¸»é¢˜å…³é”®è¯æƒé‡å›¾</a>\n",
    "        <a class=\"nav-btn\" href=\"hierarchy.html\" target=\"chart_frame\">ğŸ“Š  {year_range}å¹´{data_source}ä¸»é¢˜å±‚æ¬¡èšç±»æ ‘çŠ¶å›¾</a>\n",
    "        <a class=\"nav-btn\" href=\"documents.html\" target=\"chart_frame\">ğŸ“  {year_range}å¹´{data_source}ä¸»é¢˜åˆ†å¸ƒæ•£ç‚¹å›¾</a>\n",
    "        <a class=\"nav-btn\" href=\"topic_overtime_merged.html\" target=\"chart_frame\">âŒš {year_range}å¹´{data_source}ä¸»é¢˜æ—¶åºå›¾</a>\n",
    "        <a class=\"nav-btn\" href=\"topics_over_time_value.html\" target=\"chart_frame\">âŒš {year_range}å¹´{data_source}ä¸»é¢˜å¹´ä»½çŸ©é˜µ</a>\n",
    "    \n",
    "    </nav>\n",
    "\n",
    "    <iframe name=\"chart_frame\" id=\"content-frame\" src=\"report_{year_range}_{data_source}_{version}.html\"></iframe>\n",
    "\n",
    "    <script>\n",
    "        const buttons = document.querySelectorAll('.nav-btn');\n",
    "        buttons.forEach(btn => {{\n",
    "            btn.addEventListener('click', function() {{\n",
    "                buttons.forEach(b => b.classList.remove('active'));\n",
    "                this.classList.add('active');\n",
    "            }});\n",
    "        }});\n",
    "        // é»˜è®¤é«˜äº®ç¬¬ä¸€ä¸ªæŒ‰é’®ï¼ˆå³å‚æ•°è¯´æ˜é¡µé¢ï¼‰\n",
    "        buttons[0].classList.add('active');\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "with open(os.path.join(output_dir, f\"index_{year_range}_{data_source}_res.html\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(index_content)\n",
    "\n",
    "print(f\"ğŸ‰ ç»“æœå¯è§†åŒ–å·²å®Œæˆï¼å·²è¯·æ‰“å¼€æ–‡ä»¶å¤¹: {output_dir}æŸ¥çœ‹\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
