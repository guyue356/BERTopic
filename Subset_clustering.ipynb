{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07591d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®æ—¶æ£€æµ‹å¤–éƒ¨å‡½æ•°æ›´æ–°\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764d10dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "# 1. è®¾ç½®å›½å†…é•œåƒæº\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "from bertopic import BERTopic\n",
    "import torch # æ–°å¢ï¼šå¯¼å…¥PyTorchï¼ˆsentence_transformersçš„åº•å±‚ï¼‰\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d02ee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c59150",
   "metadata": {},
   "source": [
    "# (Config)å­æ•°æ®é›†ä¸»é¢˜èšç±»å‚æ•°è®¾ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a229cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------ é…ç½®åŒº -------------------------------\n",
    "docs_original = [] # å­˜æ”¾å­æ•°æ®é›†\n",
    "sub_timestamps = [] # å­˜æ”¾æ—¶é—´æˆ³\n",
    "target_indices = [] # å­˜æ”¾ç›®æ ‡ç´¢å¼•ï¼Œæ–¹ä¾¿è·å–è¯å‘é‡åµŒå…¥\n",
    "\n",
    "# ç‰ˆæœ¬æ§åˆ¶\n",
    "version = 'V0'\n",
    "# æ—¶é—´æ®µæ§åˆ¶\n",
    "start_time = 2000\n",
    "end_time = 2005\n",
    "year_range = f'{start_time}-{end_time}'\n",
    "\n",
    "# æ•°æ®æºæ§åˆ¶\n",
    "data_source = 'GFä¸“åˆ©'\n",
    "\n",
    "model_name = \"all-mpnet-base-v2\"\n",
    "\n",
    "# --- é…ç½®åŒºï¼šUMAP å‚æ•°è®¾ç½® ---\n",
    "umap_params = {\n",
    "    \"n_neighbors\": 15,\n",
    "    \"n_components\": 5,\n",
    "    \"min_dist\": 0.0,\n",
    "    \"metric\": 'cosine',\n",
    "    \"random_state\": 5,\n",
    "    \"low_memory\": True\n",
    "}\n",
    "\n",
    "vectorizer_params = {\n",
    "    \"ngram_range\": (1, 3), # è¯ç»„èŒƒå›´ï¼š1-3ä¸ªè¯\n",
    "    \"min_df\": 3, # è¿‡æ»¤ä½é¢‘å™ªå£°ï¼Œå¯¹å¤§æ ·æœ¬éå¸¸é‡è¦\n",
    "    \"max_features\": 100000 # é˜²æ­¢å†…å­˜æº¢å‡º\n",
    "}\n",
    "\n",
    "# --- HDBSCANå‚æ•°è®¾ç½® ---\n",
    "HDBSCAN_cfg = {\n",
    "    \"min_samples\": 10,\n",
    "    \"metric\": 'euclidean',\n",
    "    \"prediction_data\": True\n",
    "}\n",
    "\n",
    "# HDBSCANç½‘æ ¼æœç´¢èŒƒå›´\n",
    "search_sizes = [15, 20, 30, 50, 70,100,150,200,250,300]\n",
    "# è®¾å®šä½ æœŸæœ›çš„ä¸»é¢˜æ•°é‡èŒƒå›´ï¼ˆä¾‹å¦‚ 20 åˆ° 100 ä¸ªï¼‰\n",
    "min_expected_topics = 20\n",
    "max_expected_topics = 50\n",
    "\n",
    "# --- Step 2: åŠ è½½å…¨é‡åµŒå…¥å‘é‡ ---\n",
    "with open(r'results\\embedding_results\\embeddings_patents_zf_amb_slide_window3.pkl', 'rb') as f:\n",
    "    full_embeddings = pickle.load(f)\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "ä½ æ˜¯ä¸€åä¸“ä¸šçš„å›½é˜²ä¸“åˆ©ä¸æŠ€æœ¯åˆ†æä¸“å®¶ï¼Œæ“…é•¿ä»æŠ€æœ¯å…³é”®è¯ä¸­æç‚¼æ ¸å¿ƒä¸»é¢˜æ–¹å‘ã€‚\n",
    "\n",
    "ã€è¾“å…¥æ•°æ®æ ¼å¼ã€‘\n",
    "ç”¨æˆ·å°†æä¾›ä¸€ä¸ªPythonå­—å…¸ï¼š\n",
    "- é”®ï¼ˆkeyï¼‰ï¼šä¸»é¢˜ç´¢å¼•ç¼–å·ï¼ˆæ•´æ•°ï¼Œå¦‚0, 1, 2...ï¼‰\n",
    "- å€¼ï¼ˆvalueï¼‰ï¼šè¯¥ä¸»é¢˜çš„10ä¸ªè‹±æ–‡å…³é”®è¯å­—ç¬¦ä¸²ï¼Œä»¥è‹±æ–‡é€—å·åˆ†éš”\n",
    "- å…³é”®è¯å·²æŒ‰é‡è¦æ€§é™åºæ’åˆ—\n",
    "\n",
    "ã€æ ¸å¿ƒä»»åŠ¡ã€‘\n",
    "ä¸ºæ¯ä¸ªä¸»é¢˜ç”Ÿæˆä¸€ä¸ªä¸­æ–‡ä¸»é¢˜åç§°ï¼Œè¦æ±‚ï¼š\n",
    "1. **ä¿å®ˆæ¦‚æ‹¬**ï¼šåŸºäºå…³é”®è¯çš„å…±åŒæŠ€æœ¯å†…æ¶µï¼Œæå–\"ä¸Šä½æŠ€æœ¯æ–¹å‘\"\n",
    "2. **æƒé‡ä¼˜å…ˆ**ï¼šä¸»è¦ä¾æ®å‰3-5ä¸ªé«˜æƒé‡å…³é”®è¯ï¼Œåéƒ¨å…³é”®è¯ä»…å‚è€ƒ\n",
    "3. **é¿å…æ‰©å±•**ï¼šä¸å¼•å…¥æ–°æ¦‚å¿µï¼Œä¸æ‰©å±•åº”ç”¨åœºæ™¯ï¼Œä¸åšè¿‡åº¦æ¨æ–­\n",
    "4. **å¤„ç†æ¨¡ç³Š**ï¼šè‹¥å…³é”®è¯åˆ†æ•£ï¼Œä½¿ç”¨æ›´æŠ½è±¡çš„åç§°ï¼ˆå¦‚\"ç»¼åˆæŠ€æœ¯\"ï¼‰\n",
    "\n",
    "ã€ä¸»é¢˜å‘½åè§„åˆ™ã€‘\n",
    "- åç§°åº”ä½“ç°å›½é˜²/å†›äº‹æŠ€æœ¯ç‰¹ç‚¹\n",
    "- ä½¿ç”¨æ ‡å‡†æŠ€æœ¯æœ¯è¯­ï¼Œé¿å…å£è¯­åŒ–\n",
    "- é•¿åº¦æ§åˆ¶åœ¨6-15ä¸ªæ±‰å­—ä¸ºå®œ\n",
    "- æ ¼å¼ï¼š\"{ä¸»é¢˜åºå·}. {åç§°}\"ï¼Œåºå·ä»1å¼€å§‹è¿ç»­ç¼–å·\n",
    "\n",
    "ã€è¾“å‡ºè¦æ±‚ã€‘\n",
    "- ä»…è¾“å‡ºåˆæ³•çš„JSONå¯¹è±¡ï¼Œæ— ä»»ä½•é¢å¤–æ–‡æœ¬\n",
    "- JSONç»“æ„ï¼š{\"ä¸»é¢˜ç´¢å¼•\": \"åºå·.ä¸»é¢˜åç§°\"}\n",
    "- ä¸»é¢˜ç´¢å¼•ä¸è¾“å…¥ä¿æŒä¸€è‡´\n",
    "- ç¤ºä¾‹è¾“å‡ºï¼š{\"0\": \"1.é›·è¾¾æ¢æµ‹\", \"1\": \"2.å¤åˆææ–™åˆ¶å¤‡\",\"2\": \"3.éŸ³é¢‘å¤„ç†ä¸é™å™ª\"}\n",
    "\n",
    "ã€æ³¨æ„äº‹é¡¹ã€‘\n",
    "- å…³é”®è¯å¯èƒ½å­˜åœ¨è¯å½¢å˜åŒ–ï¼ˆå•å¤æ•°ç­‰ï¼‰ï¼Œç†è§£å…¶æ ¸å¿ƒè¯­ä¹‰\n",
    "- å›½é˜²é¢†åŸŸç‰¹æœ‰æœ¯è¯­åº”ä¿ç•™ä¸“ä¸šæ€§\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f5150f",
   "metadata": {},
   "source": [
    "# åŸå§‹æ•°æ®åŠ è½½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74355dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: åŒæ­¥ç­›é€‰æ–‡æ¡£å’Œæ—¶é—´æˆ³ ---\n",
    "with open('data\\patents_zf.json', 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "    \n",
    "for i, item in enumerate(data):\n",
    "    year = int(item['year'])\n",
    "    if start_time <= year <= end_time:\n",
    "        target_indices.append(i)\n",
    "        docs_original.append(item['combined_text'])\n",
    "        # è¿™é‡Œçš„å¹´ä»½å³ä¸ºæ—¶é—´æˆ³ï¼ŒBERTopic æ”¯æŒæ•´æ•°å¹´ä»½æˆ–æ ‡å‡†æ—¥æœŸæ ¼å¼\n",
    "        sub_timestamps.append(year) \n",
    "\n",
    "docs_original = [item['combined_text'] for item in data]\n",
    "\n",
    "# æ•°æ®æ¸…æ´—\n",
    "def preprocess_all(texts):\n",
    "    cleaned_list = []\n",
    "    for t in texts:\n",
    "        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦å’Œå¤šä½™ç©ºæ ¼\n",
    "        t = re.sub(r\"[^\\w\\s\\.,;]\", \" \", t) # åªä¿ç•™å­—æ¯ã€æ•°å­—ã€ç©ºæ ¼å’Œå‡ ç§æ ‡ç‚¹\n",
    "        t = re.sub(r\"\\s+\", \" \", t).strip() # ç§»é™¤å¤šä½™ç©ºæ ¼\n",
    "        cleaned_list.append(t)\n",
    "    return cleaned_list\n",
    "\n",
    "# è¿è¡Œ\n",
    "# æ£€æŸ¥æ¸…æ´—æ•ˆæœ\n",
    "sub_docs = preprocess_all(docs_original)\n",
    "\n",
    "if len(sub_docs) == len(sub_timestamps):\n",
    "    print(f'å½“å‰æ—¶é—´æ®µä¸º{start_time}-{end_time}å¹´ï¼Œå…±è·å–æ•°æ®{len(sub_docs)}æ¡ï¼Œç°åœ¨å¼€å§‹èšç±»â€¦â€¦')\n",
    "else:\n",
    "    print('éƒ¨åˆ†æ•°æ®ç¼ºå¤±å¹´ä»½ä¿¡æ¯ï¼Œè¯·æ£€æŸ¥åŸå§‹æ•°æ®')\n",
    "\n",
    "print(sub_timestamps[:3])\n",
    "for i in sub_docs[:3]: \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82052f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 3: è·å–å­é›†å‘é‡ ---\n",
    "# å‡è®¾ full_embeddings æ˜¯ numpy æ•°ç»„æ ¼å¼\n",
    "sub_embeddings = full_embeddings[target_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44735a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stopwords(file_path):\n",
    "    \"\"\"ä»JSONæ–‡ä»¶åŠ è½½åœç”¨è¯åˆ—è¡¨\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            stopwords = json.load(f)\n",
    "        print(f\"å·²åŠ è½½ {len(stopwords['common'])} ä¸ªåœç”¨è¯\")\n",
    "        return stopwords['common']  # è½¬æ¢ä¸ºé›†åˆæé«˜æŸ¥æ‰¾æ•ˆç‡\n",
    "    except FileNotFoundError:\n",
    "        print(f\"é”™è¯¯ï¼šæ–‡ä»¶ {file_path} ä¸å­˜åœ¨\")\n",
    "        return set()\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"é”™è¯¯ï¼šæ–‡ä»¶ {file_path} ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼\")\n",
    "        return set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfec526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ç»Ÿä¸€å®šä¹‰è·¯å¾„\n",
    "local_model_path = f\"./my_models/{model_name}\"  # å›ºå®šè·¯å¾„\n",
    "\n",
    "# 2. æ£€æŸ¥å¹¶åŠ è½½æ¨¡å‹\n",
    "if not os.path.exists(local_model_path):\n",
    "    print(f\"æ¨¡å‹ä¸å­˜åœ¨ï¼Œæ­£åœ¨ä¸‹è½½å¹¶ä¿å­˜åˆ°æœ¬åœ°: {model_name}\")\n",
    "    # ç›´æ¥ä»huggingfaceä¸‹è½½\n",
    "    sentence_model = SentenceTransformer(model_name)\n",
    "    # ä¿å­˜åˆ°æœ¬åœ°\n",
    "    sentence_model.save(local_model_path)\n",
    "    print(f\"æ¨¡å‹å·²ä¿å­˜è‡³ï¼š{local_model_path}\")\n",
    "else:\n",
    "    print(f\"æ¨¡å‹å·²å­˜åœ¨ï¼Œä»æœ¬åœ°åŠ è½½: {local_model_path}\")\n",
    "    # ä»æœ¬åœ°åŠ è½½\n",
    "    sentence_model = SentenceTransformer(local_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb5087a",
   "metadata": {},
   "source": [
    "# UMAPé™ç»´/HDBSCANç½‘æ ¼æœç´¢\n",
    "\n",
    "- åœ¨ä¸“åˆ©èšç±»ä¸­ï¼Œâ€œå™ªå£°æ¯”ä¾‹â€ä¸æ˜¯å”¯ä¸€çš„æŒ‡æ ‡ï¼Œç”šè‡³ä¸æ˜¯æœ€é‡è¦çš„æŒ‡æ ‡ã€‚\n",
    "- æˆ‘ä»¬çš„ç›®æ ‡æ˜¯åœ¨ä¿æŒ**ä¸»é¢˜å¯è§£é‡Šæ€§ï¼ˆä¸»é¢˜æ•°é€‚ä¸­ï¼‰å’Œå™ªå£°ç‡ï¼ˆé€šå¸¸ 20%-40% æ˜¯æ­£å¸¸çš„ï¼‰**ä¹‹é—´æ‰¾åˆ°å¹³è¡¡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba60efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## UMAPé™ç»´\n",
    "umap_model = UMAP(**umap_params) # ä½¿ç”¨è§£åŒ…è¯­æ³•ï¼Œæ–¹ä¾¿è°ƒæ•´\n",
    "umap_embeddings = umap_model.fit_transform(sub_embeddings)\n",
    "print('âœ”UMAPé™ç»´å®Œæˆï¼ç°åœ¨å¼€å§‹è¿›è¡ŒHDBSCANç½‘æ ¼æœç´¢å¯»æ‰¾æœ€ä½³min_cluster_sizeâ€¦â€¦')\n",
    "\n",
    "best_topics = None\n",
    "best_m_size = None\n",
    "best_score = float('inf')\n",
    "\n",
    "search_history = [] # æ–°å¢ï¼šç”¨äºè®°å½•ç½‘æ ¼æœç´¢è¿‡ç¨‹\n",
    "\n",
    "print(f\"{'Size':<10} | {'ä¸»é¢˜æ•°':<8} | {'è´Ÿæ ·æœ¬æ•°':<10} | {'å™ªå£°æ¯”ä¾‹':<10} | {'è€—æ—¶':<8}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for m_size in search_sizes:\n",
    "    start_t = time.time()\n",
    "    \n",
    "    clusterer = HDBSCAN(**HDBSCAN_cfg,min_cluster_size=m_size)\n",
    "    \n",
    "    labels = clusterer.fit_predict(umap_embeddings)\n",
    "    \n",
    "    # è®¡ç®—æŒ‡æ ‡\n",
    "    n_outliers = (labels == -1).sum() # è´Ÿæ ·æœ¬æ•°\n",
    "    n_topics = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    outlier_perc = n_outliers / len(labels)\n",
    "    duration = time.time() - start_t\n",
    "\n",
    "    # ä¿å­˜å†å²è®°å½•\n",
    "    res = {\n",
    "        \"min_cluster_size\": m_size,\n",
    "        \"n_topics\": n_topics,\n",
    "        \"n_outliers\": n_outliers,\n",
    "        \"outlier_perc\": f\"{outlier_perc:.1%}\",\n",
    "        \"duration\": f\"{duration:.1f}s\",\n",
    "        \"is_best\": False\n",
    "    }\n",
    "    search_history.append(res)\n",
    "\n",
    "    # ç­›é€‰é€»è¾‘ï¼šé¦–å…ˆè¦åœ¨åˆç†çš„ä¸»é¢˜æ•°èŒƒå›´å†…ï¼Œç„¶åé€‰å™ªå£°æœ€å°çš„\n",
    "    if min_expected_topics <= n_topics <= max_expected_topics:\n",
    "        if outlier_perc < best_score:\n",
    "            best_topics = n_topics\n",
    "            best_score = outlier_perc\n",
    "            best_m_size = m_size\n",
    "    \n",
    "\n",
    "    print(f\"{m_size:<10} | {n_topics:<10} | {n_outliers:<12} | {outlier_perc:<12.1%} | {duration:<8.1f}s\")\n",
    "print(\"-\" * 65)\n",
    "if best_m_size is None:\n",
    "    print(\"æœªåœ¨é¢„è®¾ä¸»é¢˜æ•°èŒƒå›´å†…æ‰¾åˆ°å‚æ•°ï¼Œå»ºè®®è°ƒä½ min_dist æˆ–æ£€æŸ¥ UMAP æ•ˆæœ\")\n",
    "else:\n",
    "    print(f\"ğŸ† ç¬¦åˆæ¡ä»¶çš„è´Ÿæ ·æœ¬æ•°æœ€å°‘çš„å‚æ•°å€¼: min_cluster_size = {best_m_size} (è´Ÿæ ·æœ¬æ¯”ä¾‹: {best_score:.1%},ä¸»é¢˜æ•°ï¼š{best_topics})\")\n",
    "\n",
    "# æ ‡è®°æœ€ä¼˜å‚æ•°\n",
    "for item in search_history:\n",
    "    if item[\"min_cluster_size\"] == best_m_size:\n",
    "        item[\"is_best\"] = True\n",
    "\n",
    "## HDBSCANèšç±»\n",
    "best_clusterer = HDBSCAN(**HDBSCAN_cfg,min_cluster_size=best_m_size)\n",
    "labels = best_clusterer.fit_predict(umap_embeddings)\n",
    "\n",
    "# åŠ è½½åœç”¨è¯\n",
    "stop_words = load_stopwords('data\\stopwords.json')\n",
    "# åˆ›å»ºCountVectorizeræ¨¡å‹,è‡ªå®šä¹‰åœç”¨è¯\n",
    "vectorizer_model = CountVectorizer(\n",
    "    **vectorizer_params,\n",
    "    stop_words = stop_words\n",
    "    )\n",
    "\n",
    "# åˆå§‹åŒ– BERTopic æ—¶å¸¦ä¸Šå®ƒ\n",
    "topic_model = BERTopic(\n",
    "  embedding_model=sentence_model,\n",
    "  vectorizer_model=vectorizer_model,\n",
    "  umap_model=umap_model,       # åŠ ä¸Šè¿™ä¸€è¡Œ\n",
    "  hdbscan_model=best_clusterer # åŠ ä¸Šè¿™ä¸€è¡Œ\n",
    ")\n",
    "#ä¼ å…¥è®­ç»ƒå¥½çš„è¯å‘é‡ï¼Œfit_transformer()åŒ…æ‹¬äº†UMAPé™ç»´+HDBSCANèšç±»ï¼Œä¸å»ºè®®è¿™ä¹ˆåšï¼Œå¯ä»¥å°†å…¶æ‹†å¼€å‡å°‘è®¡ç®—\n",
    "#topics, probs = topic_model.fit_transform(docs, embeddings=embeddings,y = labels) \n",
    "#probè®¡ç®—å¾ˆèŠ±æ—¶é—´\n",
    "topics, _ = topic_model.fit_transform(sub_docs, embeddings=sub_embeddings)\n",
    "# ä¿å­˜æ•´ä¸ªä¸»é¢˜æ¨¡å‹\n",
    "\n",
    "save_path = rf\"results\\topic_models\\bertopic_{data_source}_{year_range}_{version}\"\n",
    "topic_model.save(save_path)\n",
    "print(rf\"ä¸»é¢˜æ¨¡å‹å·²ä¿å­˜åˆ° results\\topic_models\\bertopic_{data_source}_{year_range}_{version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb6e76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model = BERTopic.load(rf\"results\\topic_models\\bertopic_patents_zf_{year_range}_{version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f03f138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460a4e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è·å–æ‰€æœ‰ä¸»é¢˜çš„å­—å…¸ {topic_id: [(word, score), ...]}\n",
    "all_topics_dict = topic_model.get_topics()\n",
    "# è¿‡æ»¤æ‰ -1 (å™ªå£°)ï¼Œå¹¶å°†æ¯ä¸ªè¯åˆ—è¡¨è½¬ä¸ºé€—å·è¿æ¥çš„å­—ç¬¦ä¸²\n",
    "clean_topics_dict = {\n",
    "    topic_id: \",\".join([word for word, score in words_list])\n",
    "    for topic_id, words_list in all_topics_dict.items()\n",
    "    if topic_id != -1\n",
    "}\n",
    "\n",
    "for item in clean_topics_dict.items():\n",
    "    print(item)\n",
    "    \n",
    "# æ£€æŸ¥ç»“æœ\n",
    "print(f'å·²è·å–{len(clean_topics_dict)}ä¸ªä¸»é¢˜çš„è¯¦ç»†ä¿¡æ¯ï¼Œç°åœ¨é€šè¿‡AIåˆ¤æ–­ä¸»é¢˜åç§°â€¦â€¦') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb99083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AIè¯†åˆ«\n",
    "user_prompt = f\"è¯·åˆ†æä»¥ä¸‹ä¸»é¡Œå…³é”®è¯ï¼Œå¹¶è¿”å› JSON å­—å…¸ï¼š\\n{clean_topics_dict}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5468b221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import re\n",
    "# åŠ è½½ .env æ–‡ä»¶\n",
    "load_dotenv(\".env\")\n",
    "API_KEY=os.environ.get('DEEPSEEK_API_KEY')\n",
    "deepseek_chat_model = \"deepseek-chat\" # DeepSeek-V3.2çš„éæ€è€ƒæ¨¡å¼\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url=\"https://api.deepseek.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e086f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AIè¯†åˆ«æ™ºèƒ½ä½“å‚æ•°è®¾ç½®ï¼šåˆ›å»ºä¸“é—¨ç”¨äºåœ°å€æ¨ç†çš„ LLM å®ä¾‹\n",
    "Deepseek_reasponse = client.chat.completions.create(\n",
    "    model=deepseek_chat_model,\n",
    "    messages=[ # å¯¹è¯æ¶ˆæ¯åˆ—è¡¨\n",
    "        {\"role\": \"system\", \"content\": system_prompt}, # ç³»ç»Ÿæç¤ºè¯ï¼Œå®šä¹‰åŠ©æ‰‹çš„è¡Œä¸º\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ],\n",
    "    response_format={'type': 'json_object'}, #å¼ºåˆ¶jsonæ ¼å¼è¿”å›\n",
    "    stream=False # éæµå¼å“åº”ï¼ˆä¸€æ¬¡æ€§è¿”å›å®Œæ•´ç»“æœï¼‰\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513bee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = json.loads(Deepseek_reasponse.choices[0].message.content)\n",
    "#content = re.sub(r\"^```json\\s*|\\s*```$\", \"\", content.strip())\n",
    "# å°†é”®è½¬ä¸ºæ•´å‹\n",
    "formatted_labels = {int(k): v for k, v in content.items()}\n",
    "print(formatted_labels)\n",
    "\n",
    "# ä½¿ç”¨è‡ªå®šä¹‰æ ‡ç­¾ï¼ˆéœ€è¦å…ˆè®¾ç½®ï¼‰\n",
    "topic_model.set_topic_labels(formatted_labels)\n",
    "\n",
    "# é™è‡³äºŒç»´ï¼Œå†å¯è§†åŒ–\n",
    "reduced_embeddings = UMAP(n_neighbors=30, n_components=2, min_dist=0.0, metric='cosine').fit_transform(sub_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801cc564",
   "metadata": {},
   "source": [
    "# æ•°æ®å¯è§†åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5904cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å±‚æ¬¡èšç±»\n",
    "hierarchical_topics = topic_model.hierarchical_topics(sub_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a8ee5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from report_generator import generate_bertopic_report\n",
    "# --- 0. åŸºç¡€è®¾ç½® ---\n",
    "title_base = f'{year_range}å¹´{data_source}æ•°æ®Bertopicä¸»é¢˜èšç±»ç»“æœä¸€è§ˆè¡¨-{version}'\n",
    "output_dir = f\"BERTopic_Results_Subset_{year_range}_{data_source}_{version}\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# --- å‚æ•°è¯´æ˜ ---\n",
    "report_name = os.path.join(output_dir, f\"report_{year_range}_{data_source}_{version}.html\")\n",
    "#generate_report(umap_params, search_history, best_m_size, model_name, report_name)\n",
    "\n",
    "generate_bertopic_report(umap_cfg = umap_params, \n",
    "                         HDBSCAN_cfg=HDBSCAN_cfg,\n",
    "                         vectorizer_cfg = vectorizer_params,\n",
    "                         history= search_history,\n",
    "                         best_size = best_m_size,\n",
    "                         model_name = model_name, \n",
    "                         output_path = report_name)\n",
    "\n",
    "# --- 1. ç”Ÿæˆå›¾è¡¨ (æŒ‰ç…§ä½ æƒ³è¦çš„é¡ºåº) ---\n",
    "#-------------------------------------------------------------------------\n",
    "# [å›¾ A] ä¸»é¢˜å…³é”®è¯æ¡å½¢å›¾ - å­˜ä¸º barchart.html\n",
    "fig_barchart = topic_model.visualize_barchart(\n",
    "    top_n_topics=len(formatted_labels),\n",
    "    custom_labels=True,\n",
    "    n_words=10,\n",
    "    height=400,\n",
    "    title=f\"{year_range}å¹´{data_source}å„ä¸»é¢˜å…³é”®è¯çš„c-TF-IDFæƒé‡å¾—åˆ†æ¡å½¢å›¾\",\n",
    ")\n",
    "\n",
    "fig_barchart.update_layout(\n",
    "    # å› ä¸ºæ¯è¡Œå¢åŠ äº†å­å›¾ï¼Œå»ºè®®å¢åŠ æ€»å®½åº¦ä»¥é˜²é‡å \n",
    "    width=1500, \n",
    "    # ç»Ÿä¸€å­—ä½“æ ·å¼\n",
    "    font=dict(family=\"KaiTi\", size=16),\n",
    "    title_font=dict(family=\"KaiTi\", size=36, color=\"black\", weight=\"bold\")\n",
    ")\n",
    "path_barchart = os.path.join(output_dir, \"barchart.html\")\n",
    "fig_barchart.write_html(path_barchart)\n",
    "#-------------------------------------------------------------------------\n",
    "# [å›¾ B] å±‚æ¬¡èšç±»å›¾ - å­˜ä¸º hierarchy.html\n",
    "fig_hierarchy = topic_model.visualize_hierarchy(\n",
    "    hierarchical_topics=hierarchical_topics,\n",
    "    custom_labels=True,\n",
    "    title=f\"{year_range}å¹´{data_source}ä¸»é¢˜å±‚æ¬¡èšç±»å›¾\",\n",
    "    height=800\n",
    ")\n",
    "fig_hierarchy.update_layout(\n",
    "    title_x=0.5,\n",
    "    # å› ä¸ºæ¯è¡Œå¢åŠ äº†å­å›¾ï¼Œå»ºè®®å¢åŠ æ€»å®½åº¦ä»¥é˜²é‡å \n",
    "    width=1500, \n",
    "    # ç»Ÿä¸€å­—ä½“æ ·å¼\n",
    "    font=dict(family=\"KaiTi\", size=16),\n",
    "    title_font=dict(family=\"KaiTi\", size=30, color=\"black\", weight=\"bold\")\n",
    ")\n",
    "path_hierarchy = os.path.join(output_dir, \"hierarchy.html\")\n",
    "fig_hierarchy.write_html(path_hierarchy)\n",
    "#-------------------------------------------------------------------------\n",
    "# [å›¾ C] æ–‡æ¡£åˆ†å¸ƒæ•£ç‚¹å›¾ - å­˜ä¸º documents.html\n",
    "fig_documents = topic_model.visualize_documents(\n",
    "    #docs=[doc[:150] + \"...\" for doc in sub_docs],\n",
    "    docs=[str(doc)[:150] + \"...\" for doc in sub_docs if doc is not None],\n",
    "    reduced_embeddings=reduced_embeddings,\n",
    "    custom_labels=True,\n",
    "    hide_document_hover=False\n",
    ")\n",
    "# æ›´æ–°æ•£ç‚¹å›¾æ ·å¼\n",
    "fig_documents.update_layout(\n",
    "    title=f\"{year_range}å¹´{data_source}ä¸»é¢˜åˆ†å¸ƒå›¾\",\n",
    "    title_x=0.5,\n",
    "    width=1500,\n",
    "    height=1200,\n",
    "    margin=dict(l=80, r=80, t=100, b=80), # è®¾ç½®å¯¹ç§°è¾¹è·\n",
    "    font=dict(family=\"KaiTi\", size=16, color=\"black\"),\n",
    "    title_font=dict(family=\"KaiTi\", size=30, color=\"black\", weight=\"bold\")\n",
    ")\n",
    "path_documents = os.path.join(output_dir, \"documents.html\")\n",
    "fig_documents.write_html(path_documents)\n",
    "#-------------------------------------------------------------------------\n",
    "# [å›¾ D] ä¸»é¢˜æ—¶åºå›¾ - å­˜ä¸º hierarchy.html\n",
    "topics_over_time = topic_model.topics_over_time(sub_docs, sub_timestamps, global_tuning=False, evolution_tuning=False)\n",
    "fig_topic_time = topic_model.visualize_topics_over_time(\n",
    "    topics_over_time,\n",
    "    custom_labels=True)\n",
    "# æ›´æ–°æ•£ç‚¹å›¾æ ·å¼\n",
    "fig_topic_time.update_layout(\n",
    "    title=f\"{year_range}å¹´{data_source}ä¸»é¢˜æ—¶åºå›¾\",\n",
    "    title_x=0.5,\n",
    "    width=1500,\n",
    "    height=800,\n",
    "    font=dict(family=\"KaiTi\", size=16, color=\"black\"),\n",
    "    title_font=dict(family=\"KaiTi\", size=30, color=\"black\", weight=\"bold\")\n",
    ")\n",
    "path_topic_time = os.path.join(output_dir, \"topic_overtime_merged.html\")\n",
    "fig_topic_time.write_html(path_topic_time)\n",
    "# --- 2. åˆ›å»ºå¯¼èˆªç´¢å¼•é¡µ (index.html) ---\n",
    "# æ³¨æ„ï¼šæˆ‘åœ¨è¿™é‡ŒåŒæ­¥è°ƒæ•´äº†æŒ‰é’®é¡ºåºå’Œ iframe çš„é»˜è®¤ src\n",
    "index_content = f\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"zh-CN\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <title>{title_base}</title>\n",
    "    <style>\n",
    "        body {{ font-family: 'Microsoft YaHei', sans-serif; margin: 0; display: flex; flex-direction: column; height: 100vh; background-color: #f4f7f6; }}\n",
    "        header {{ background: #2c3e50; color: white; padding: 15px 25px; display: flex; justify-content: space-between; align-items: center; box-shadow: 0 2px 5px rgba(0,0,0,0.2); }}\n",
    "        h1 {{ margin: 0; font-size: 20px; }}\n",
    "        nav {{ background: #ecf0f1; padding: 10px; display: flex; gap: 10px; border-bottom: 1px solid #ddd; }}\n",
    "        .nav-btn {{ \n",
    "            padding: 8px 15px; background: white; border: 1px solid #bdc3c7; border-radius: 4px; \n",
    "            cursor: pointer; text-decoration: none; color: #34495e; font-size: 14px; transition: all 0.3s;\n",
    "        }}\n",
    "        .nav-btn:hover {{ background: #3498db; color: white; border-color: #2980b9; }}\n",
    "        .nav-btn.active {{ background: #3498db; color: white; }}\n",
    "        #content-frame {{ flex-grow: 1; border: none; width: 100%; }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <header>\n",
    "        <h1>{title_base}</h1>\n",
    "        <span style=\"font-size: 12px; opacity: 0.8;\">ç‰ˆæœ¬: {version}</span>\n",
    "    </header>\n",
    "    \n",
    "    <nav>\n",
    "        <a class=\"nav-btn\" href=\"report_{year_range}_{data_source}_{version}.html\" target=\"chart_frame\">âœ¨ {year_range}å¹´{data_source}ä¸»é¢˜èšç±»å‚æ•°è¯´æ˜</a>\n",
    "        <a class=\"nav-btn\" href=\"barchart.html\" target=\"chart_frame\">ğŸ“ˆ  {year_range}å¹´{data_source}ä¸»é¢˜å…³é”®è¯æƒé‡å›¾</a>\n",
    "        <a class=\"nav-btn\" href=\"hierarchy.html\" target=\"chart_frame\">ğŸ“Š  {year_range}å¹´{data_source}ä¸»é¢˜å±‚æ¬¡èšç±»æ ‘çŠ¶å›¾</a>\n",
    "        <a class=\"nav-btn\" href=\"documents.html\" target=\"chart_frame\">ğŸ“  {year_range}å¹´{data_source}ä¸»é¢˜åˆ†å¸ƒæ•£ç‚¹å›¾</a>\n",
    "        <a class=\"nav-btn\" href=\"topic_overtime_merged.html\" target=\"chart_frame\">âŒš {year_range}å¹´{data_source}ä¸»é¢˜æ—¶åºå›¾</a>\n",
    "    \n",
    "    </nav>\n",
    "\n",
    "    <iframe name=\"chart_frame\" id=\"content-frame\" src=\"report_{year_range}_{data_source}_{version}.html\"></iframe>\n",
    "\n",
    "    <script>\n",
    "        const buttons = document.querySelectorAll('.nav-btn');\n",
    "        buttons.forEach(btn => {{\n",
    "            btn.addEventListener('click', function() {{\n",
    "                buttons.forEach(b => b.classList.remove('active'));\n",
    "                this.classList.add('active');\n",
    "            }});\n",
    "        }});\n",
    "        // é»˜è®¤é«˜äº®ç¬¬ä¸€ä¸ªæŒ‰é’®ï¼ˆå³å‚æ•°è¯´æ˜é¡µé¢ï¼‰\n",
    "        buttons[0].classList.add('active');\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "with open(os.path.join(output_dir, f\"index_{year_range}_{data_source}_res.html\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(index_content)\n",
    "\n",
    "print(f\"ğŸ‰ ç»“æœå¯è§†åŒ–å·²å®Œæˆï¼å·²è¯·æ‰“å¼€æ–‡ä»¶å¤¹: {output_dir}æŸ¥çœ‹\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
